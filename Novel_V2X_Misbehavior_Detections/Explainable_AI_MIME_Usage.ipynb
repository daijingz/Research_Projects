{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2775ff76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model expects input shape: (None, 3, 1, 12)\n",
      "[RESULT] mi_map shape: (3, 1, 12)\n",
      "[RESULT] explained_class: 0\n",
      "[RESULT] total MI sum: 51.740101\n",
      "[MIME] Saved:\n",
      " - mime_explanations\\3x1_e_bi_per_pixel_class_0.png\n",
      " - mime_explanations\\3x1_e_bi_per_channel_class_0.png\n",
      " - mime_explanations\\3x1_e_bi_per_channel_grid_class_0.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "MODEL_PATH = os.path.join(\"models\", \"veremi_images_m_2x2_e_i.keras\")\n",
    "# Provide a path to a single sample .npy; shape must match model input (H,W,C).\n",
    "# If None, a synthetic demo sample is used.\n",
    "SAMPLE_NPY = None  # e.g., r\"samples\\example_0001.npy\"\n",
    "\n",
    "# Number of perturbations per feature for MI estimation\n",
    "K = 80\n",
    "# Perturbation std (as a fraction of value range). Tune as needed.\n",
    "PERTURB_STD_FRAC = 0.10\n",
    "# Number of bins to discretize both perturbed feature values and predicted probs for MI\n",
    "N_BINS = 10\n",
    "# Set which class to explain: 'pred' for the model's predicted class, or an integer class id\n",
    "CLASS_TO_EXPLAIN = 'pred'\n",
    "\n",
    "# Value clipping range for the inputs (change if your preprocessing differs)\n",
    "CLIP_MIN, CLIP_MAX = 0.0, 1.0\n",
    "\n",
    "# Output directory\n",
    "OUTDIR = \"mime_explanations\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Channel names (guarded to fall back if count mismatches)\n",
    "CHANNEL_NAMES_DEFAULT = [\n",
    "    \"sendTime\", \"sender\", \"posx\", \"posy\",\n",
    "    \"spdx_n\", \"spdy_n\", \"aclx\", \"acly\",\n",
    "    \"hedx\", \"hedy\", \"hedx_n\", \"hedy_n\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def pick_classification_head(model, prefer_name=None):\n",
    "    \"\"\"\n",
    "    Normalize Keras outputs to a single classification probability vector.\n",
    "    Picks a head whose last-dim looks like a class dimension.\n",
    "    \"\"\"\n",
    "    outputs = model.outputs\n",
    "    if isinstance(outputs, tf.Tensor):\n",
    "        return outputs\n",
    "\n",
    "    chosen = None\n",
    "    if prefer_name is not None and hasattr(model, \"output_names\"):\n",
    "        try:\n",
    "            idx = list(model.output_names).index(prefer_name)\n",
    "            chosen = outputs[idx]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if chosen is None:\n",
    "        # Prefer any head with last-dim >= 2 (classification)\n",
    "        for t in outputs:\n",
    "            try:\n",
    "                last = int(t.shape[-1])\n",
    "                if last >= 2:\n",
    "                    chosen = t\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if chosen is None:\n",
    "        chosen = outputs[0]\n",
    "\n",
    "    return chosen\n",
    "\n",
    "def ensure_softmax_probs(logits_or_probs):\n",
    "    \"\"\"Apply softmax if necessary (handles binary or multi-class).\"\"\"\n",
    "    arr = np.asarray(logits_or_probs)\n",
    "    s = arr.sum(axis=-1, keepdims=True)\n",
    "    if np.all(arr >= -1e-6) and np.all(np.abs(s - 1.0) < 1e-3):\n",
    "        return arr\n",
    "    exps = np.exp(arr - np.max(arr, axis=-1, keepdims=True))\n",
    "    return exps / np.clip(exps.sum(axis=-1, keepdims=True), 1e-12, None)\n",
    "\n",
    "def discretize(values, n_bins):\n",
    "    \"\"\"Discretize 1D array into n_bins equal-width bins, returning bin indices [0..n_bins-1].\"\"\"\n",
    "    v = np.asarray(values).ravel()\n",
    "    vmin, vmax = np.min(v), np.max(v)\n",
    "    if vmax == vmin:\n",
    "        # Degenerate; put everything in a single bin\n",
    "        return np.zeros_like(v, dtype=int), vmin, vmax\n",
    "    edges = np.linspace(vmin, vmax, n_bins + 1)\n",
    "    bins = np.clip(np.digitize(v, edges[:-1], right=False) - 1, 0, n_bins - 1)\n",
    "    return bins, vmin, vmax\n",
    "\n",
    "def mutual_information_discrete(x_bins, y_bins, n_x_bins, n_y_bins, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Empirical MI(X;Y) with discrete bins.\n",
    "    x_bins, y_bins: integer arrays in [0..n_x_bins-1], [0..n_y_bins-1]\n",
    "    \"\"\"\n",
    "    x_bins = np.asarray(x_bins).ravel()\n",
    "    y_bins = np.asarray(y_bins).ravel()\n",
    "    assert x_bins.shape == y_bins.shape\n",
    "\n",
    "    N = len(x_bins)\n",
    "    joint = np.zeros((n_x_bins, n_y_bins), dtype=float)\n",
    "    for xb, yb in zip(x_bins, y_bins):\n",
    "        joint[xb, yb] += 1.0\n",
    "    joint /= max(N, 1)\n",
    "\n",
    "    px = joint.sum(axis=1, keepdims=True)\n",
    "    py = joint.sum(axis=0, keepdims=True)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = joint / (px @ py + eps)\n",
    "        term = joint * np.log(np.clip(ratio, eps, None))\n",
    "\n",
    "    mi = np.nansum(term)\n",
    "    return float(mi)\n",
    "\n",
    "def load_sample(sample_path, expected_shape):\n",
    "    \"\"\"Load sample matching expected (H,W,C). If None, create synthetic in [0,1].\"\"\"\n",
    "    H, W, C = expected_shape\n",
    "    if sample_path is not None and os.path.isfile(sample_path):\n",
    "        x = np.load(sample_path)\n",
    "        if x.shape != (H, W, C):\n",
    "            raise ValueError(f\"Expected sample shape {(H,W,C)}, got {x.shape}\")\n",
    "        return x.astype(np.float32)[None, ...]\n",
    "    # Fallback synthetic sample in [0,1]\n",
    "    rng = np.random.RandomState(0)\n",
    "    x = rng.rand(H, W, C).astype(np.float32)\n",
    "    return x[None, ...]\n",
    "\n",
    "class MIMEPredictor:\n",
    "    def __init__(self, model, head_tensor, h, w, c):\n",
    "        # Build a submodel that outputs the classification head\n",
    "        if isinstance(model.inputs, (list, tuple)):\n",
    "            inputs_for_submodel = list(model.inputs)\n",
    "        else:\n",
    "            inputs_for_submodel = [model.input]\n",
    "        self.head_model = tf.keras.Model(inputs=inputs_for_submodel, outputs=head_tensor)\n",
    "\n",
    "        # Keep input meta for passing the right structure later\n",
    "        self._single_input = (len(self.head_model.inputs) == 1)\n",
    "        self._input_names = getattr(self.head_model, \"input_names\", None)\n",
    "\n",
    "        # Fixed input signature to avoid retracing\n",
    "        self._sig = tf.TensorSpec(shape=[None, h, w, c], dtype=tf.float32)\n",
    "\n",
    "        @tf.function(reduce_retracing=True, input_signature=[self._sig])\n",
    "        def _predict_tf(x):\n",
    "            # Match the model's expected input structure:\n",
    "            if self._single_input:\n",
    "                # Option 1 (usually enough to remove the warning): wrap as a list\n",
    "                return self.head_model([x], training=False)\n",
    "\n",
    "                # Option 2 (even stricter by name; uncomment if you still see warnings)\n",
    "                # if self._input_names:\n",
    "                #     return self.head_model({self._input_names[0]: x}, training=False)\n",
    "                # else:\n",
    "                #     return self.head_model([x], training=False)\n",
    "            else:\n",
    "                # If you ever have multi-input, you'd map tensors accordingly here.\n",
    "                raise ValueError(\"This predictor currently supports single-input models only.\")\n",
    "\n",
    "        self._predict_tf = _predict_tf\n",
    "\n",
    "    def probs(self, xb_np):\n",
    "        x = tf.convert_to_tensor(xb_np, dtype=tf.float32)\n",
    "        out = self._predict_tf(x).numpy()\n",
    "        return ensure_softmax_probs(out)\n",
    "\n",
    "# =========================\n",
    "# MIME (local MI) explanation\n",
    "# =========================\n",
    "def mime_local_importance(predictor, x1, class_to_explain='pred',\n",
    "                          k=80, perturb_std_frac=0.10, n_bins=10,\n",
    "                          clip_min=0.0, clip_max=1.0):\n",
    "    base_probs = predictor.probs(x1)  # (1, C)\n",
    "    num_classes = base_probs.shape[-1]\n",
    "    if class_to_explain == 'pred':\n",
    "        explained_class = int(np.argmax(base_probs[0]))\n",
    "    else:\n",
    "        explained_class = int(class_to_explain)\n",
    "        if explained_class < 0 or explained_class >= num_classes:\n",
    "            raise ValueError(f\"class_to_explain out of range: {explained_class}\")\n",
    "\n",
    "    H, W, C = x1.shape[1:]\n",
    "    mi_map = np.zeros((H, W, C), dtype=np.float32)\n",
    "\n",
    "    vmin, vmax = float(np.min(x1)), float(np.max(x1))\n",
    "    if vmax == vmin:\n",
    "        vmax = vmin + 1.0\n",
    "    value_range = max(vmax - vmin, 1e-6)\n",
    "    sigma = perturb_std_frac * value_range\n",
    "\n",
    "    xb = np.repeat(x1.astype(np.float32), repeats=k, axis=0)  # (k,H,W,C), fixed shape\n",
    "\n",
    "    total_feats = H * W * C\n",
    "    idx = 0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            for ch in range(C):\n",
    "                base_val = float(x1[0, i, j, ch])\n",
    "                noise = np.random.normal(loc=0.0, scale=sigma, size=(k,))\n",
    "                pert_vals = np.clip(base_val + noise, clip_min, clip_max).astype(np.float32)\n",
    "\n",
    "                xb[:] = x1\n",
    "                xb[:, i, j, ch] = pert_vals\n",
    "\n",
    "                probs = predictor.probs(xb)          # (k, C)\n",
    "                y = probs[:, explained_class]        # (k,)\n",
    "\n",
    "                x_bins, _, _ = discretize(pert_vals, n_bins)\n",
    "                y_bins, _, _ = discretize(y, n_bins)\n",
    "                mi = mutual_information_discrete(x_bins, y_bins, n_bins, n_bins)\n",
    "                mi_map[i, j, ch] = mi\n",
    "\n",
    "                idx += 1\n",
    "                if idx % 50 == 0:\n",
    "                    print(f\"[MIME] Processed {idx}/{total_feats} features...\")\n",
    "\n",
    "    return mi_map, explained_class\n",
    "\n",
    "# =========================\n",
    "# Plotting helpers\n",
    "# =========================\n",
    "def plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR):\n",
    "    H, W, C = mi_map.shape\n",
    "\n",
    "    # Aggregate views\n",
    "    per_pixel = mi_map.sum(axis=2)\n",
    "    per_channel = mi_map.sum(axis=(0,1))\n",
    "\n",
    "    def _normalize(a):\n",
    "        a = np.asarray(a, dtype=float)\n",
    "        m, M = np.min(a), np.max(a)\n",
    "        if M > m:\n",
    "            return (a - m) / (M - m + 1e-12)\n",
    "        return np.zeros_like(a)\n",
    "\n",
    "    # Custom colormap\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap = LinearSegmentedColormap.from_list(\"wlb\", [\"white\", \"lightblue\", \"blue\"])\n",
    "\n",
    "    # Choose channel names safely\n",
    "    if len(CHANNEL_NAMES_DEFAULT) == C:\n",
    "        channel_names = CHANNEL_NAMES_DEFAULT\n",
    "    else:\n",
    "        channel_names = [f\"channel_{i}\" for i in range(C)]\n",
    "\n",
    "    # Per-pixel heatmap\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    im = plt.imshow(_normalize(per_pixel), interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f\"MIME per-pixel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.colorbar(im, label=\"normalized MI\")\n",
    "    plt.xticks(range(W)); plt.yticks(range(H))\n",
    "    path_pixel = os.path.join(outdir, f\"{H}x{W}_e_bi_per_pixel_class_{explained_class}.png\")\n",
    "    plt.savefig(path_pixel, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Per-channel bar\n",
    "    fig = plt.figure(figsize=(max(6, C*0.7), 4))\n",
    "    xs = np.arange(C)\n",
    "    plt.bar(xs, per_channel)\n",
    "    plt.xlabel(\"Channel\")\n",
    "    plt.ylabel(\"MI (sum over spatial)\")\n",
    "    plt.title(f\"MIME per-channel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.xticks(xs, channel_names, rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    path_chan = os.path.join(outdir, f\"{H}x{W}_e_bi_per_channel_class_{explained_class}.png\")\n",
    "    plt.savefig(path_chan, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Grid of channel heatmaps\n",
    "    import matplotlib.colors as mcolors\n",
    "    vmin = float(np.min(mi_map))\n",
    "    vmax = float(np.max(mi_map))\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    n_cols = 4\n",
    "    n_rows = int(math.ceil(C / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "    axs = np.atleast_1d(axs).reshape(n_rows, n_cols)\n",
    "    im_last = None\n",
    "    for ch in range(C):\n",
    "        r, c = divmod(ch, n_cols)\n",
    "        ax = axs[r, c]\n",
    "        im_last = ax.imshow(mi_map[:,:,ch], interpolation='nearest', norm=norm, cmap=cmap)\n",
    "        ax.set_title(channel_names[ch], fontsize=9)\n",
    "        ax.set_xticks(range(W)); ax.set_yticks(range(H))\n",
    "    for idx in range(C, n_rows*n_cols):\n",
    "        r, c = divmod(idx, n_cols)\n",
    "        axs[r, c].axis(\"off\")\n",
    "    cbar = fig.colorbar(im_last, ax=axs, shrink=0.95, pad=0.02)\n",
    "    cbar.set_label(\"Mutual Information (MI)\")\n",
    "    fig.suptitle(f\"MIME per-feature MI by channel (class {explained_class}) [{H}x{W}]\", y=0.995, fontsize=12)\n",
    "    path_grid = os.path.join(outdir, f\"{H}x{W}_e_bi_per_channel_grid_class_{explained_class}.png\")\n",
    "    plt.savefig(path_grid, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"[MIME] Saved:\")\n",
    "    print(\" -\", path_pixel)\n",
    "    print(\" -\", path_chan)\n",
    "    print(\" -\", path_grid)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    # Infer (H, W, C) from the model\n",
    "    _, H, W, C = model.input_shape\n",
    "    print(f\"[INFO] Model expects input shape: (None, {H}, {W}, {C})\")\n",
    "\n",
    "    # Build predictor with the correct spatial dims and channels\n",
    "    head = pick_classification_head(model, prefer_name=\"classification_output\")\n",
    "    predictor = MIMEPredictor(model, head_tensor=head, h=H, w=W, c=C)\n",
    "\n",
    "    # Load sample of correct shape (or synthesize)\n",
    "    x1 = load_sample(SAMPLE_NPY, expected_shape=(H, W, C)).astype(np.float32)\n",
    "    x1 = np.clip(x1, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "    # Peek prediction (uses cached predictor)\n",
    "    base_probs = predictor.probs(x1)\n",
    "    cexp = 0\n",
    "\n",
    "    mi_map, explained_class = mime_local_importance(\n",
    "        predictor, x1,\n",
    "        class_to_explain=cexp,\n",
    "        k=K,\n",
    "        perturb_std_frac=PERTURB_STD_FRAC,\n",
    "        n_bins=N_BINS,\n",
    "        clip_min=CLIP_MIN,\n",
    "        clip_max=CLIP_MAX\n",
    "    )\n",
    "\n",
    "    print(f\"[RESULT] mi_map shape: {mi_map.shape}\")\n",
    "    print(f\"[RESULT] explained_class: {explained_class}\")\n",
    "    print(f\"[RESULT] total MI sum: {mi_map.sum():.6f}\")\n",
    "\n",
    "    plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f1c4674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model expects input shape: (None, 3, 1, 12)\n",
      "[RESULT] mi_map shape: (3, 1, 12)\n",
      "[RESULT] explained_class: 1\n",
      "[RESULT] total MI sum: -0.000000\n",
      "[MIME] Saved:\n",
      " - mime_explanations\\3x1_e_bi_per_pixel_class_1.png\n",
      " - mime_explanations\\3x1_e_bi_per_channel_class_1.png\n",
      " - mime_explanations\\3x1_e_bi_per_channel_grid_class_1.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "MODEL_PATH = os.path.join(\"models\", \"veremi_images_1x3_e_i.keras\")\n",
    "# Provide a path to a single sample .npy; shape must match model input (H,W,C).\n",
    "# If None, a synthetic demo sample is used.\n",
    "SAMPLE_NPY = None  # e.g., r\"samples\\example_0001.npy\"\n",
    "\n",
    "# Number of perturbations per feature for MI estimation\n",
    "K = 80\n",
    "# Perturbation std (as a fraction of value range). Tune as needed.\n",
    "PERTURB_STD_FRAC = 0.10\n",
    "# Number of bins to discretize both perturbed feature values and predicted probs for MI\n",
    "N_BINS = 10\n",
    "# Set which class to explain: 'pred' for the model's predicted class, or an integer class id\n",
    "CLASS_TO_EXPLAIN = 'pred'\n",
    "\n",
    "# Value clipping range for the inputs (change if your preprocessing differs)\n",
    "CLIP_MIN, CLIP_MAX = 0.0, 1.0\n",
    "\n",
    "# Output directory\n",
    "OUTDIR = \"mime_explanations\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Channel names (guarded to fall back if count mismatches)\n",
    "CHANNEL_NAMES_DEFAULT = [\n",
    "    \"sendTime\", \"sender\", \"posx\", \"posy\",\n",
    "    \"spdx_n\", \"spdy_n\", \"aclx\", \"acly\",\n",
    "    \"hedx\", \"hedy\", \"hedx_n\", \"hedy_n\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def pick_classification_head(model, prefer_name=None):\n",
    "    \"\"\"\n",
    "    Normalize Keras outputs to a single classification probability vector.\n",
    "    Picks a head whose last-dim looks like a class dimension.\n",
    "    \"\"\"\n",
    "    outputs = model.outputs\n",
    "    if isinstance(outputs, tf.Tensor):\n",
    "        return outputs\n",
    "\n",
    "    chosen = None\n",
    "    if prefer_name is not None and hasattr(model, \"output_names\"):\n",
    "        try:\n",
    "            idx = list(model.output_names).index(prefer_name)\n",
    "            chosen = outputs[idx]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if chosen is None:\n",
    "        # Prefer any head with last-dim >= 2 (classification)\n",
    "        for t in outputs:\n",
    "            try:\n",
    "                last = int(t.shape[-1])\n",
    "                if last >= 2:\n",
    "                    chosen = t\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if chosen is None:\n",
    "        chosen = outputs[0]\n",
    "\n",
    "    return chosen\n",
    "\n",
    "def ensure_softmax_probs(logits_or_probs):\n",
    "    \"\"\"Apply softmax if necessary (handles binary or multi-class).\"\"\"\n",
    "    arr = np.asarray(logits_or_probs)\n",
    "    s = arr.sum(axis=-1, keepdims=True)\n",
    "    if np.all(arr >= -1e-6) and np.all(np.abs(s - 1.0) < 1e-3):\n",
    "        return arr\n",
    "    exps = np.exp(arr - np.max(arr, axis=-1, keepdims=True))\n",
    "    return exps / np.clip(exps.sum(axis=-1, keepdims=True), 1e-12, None)\n",
    "\n",
    "def discretize(values, n_bins):\n",
    "    \"\"\"Discretize 1D array into n_bins equal-width bins, returning bin indices [0..n_bins-1].\"\"\"\n",
    "    v = np.asarray(values).ravel()\n",
    "    vmin, vmax = np.min(v), np.max(v)\n",
    "    if vmax == vmin:\n",
    "        # Degenerate; put everything in a single bin\n",
    "        return np.zeros_like(v, dtype=int), vmin, vmax\n",
    "    edges = np.linspace(vmin, vmax, n_bins + 1)\n",
    "    bins = np.clip(np.digitize(v, edges[:-1], right=False) - 1, 0, n_bins - 1)\n",
    "    return bins, vmin, vmax\n",
    "\n",
    "def mutual_information_discrete(x_bins, y_bins, n_x_bins, n_y_bins, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Empirical MI(X;Y) with discrete bins.\n",
    "    x_bins, y_bins: integer arrays in [0..n_x_bins-1], [0..n_y_bins-1]\n",
    "    \"\"\"\n",
    "    x_bins = np.asarray(x_bins).ravel()\n",
    "    y_bins = np.asarray(y_bins).ravel()\n",
    "    assert x_bins.shape == y_bins.shape\n",
    "\n",
    "    N = len(x_bins)\n",
    "    joint = np.zeros((n_x_bins, n_y_bins), dtype=float)\n",
    "    for xb, yb in zip(x_bins, y_bins):\n",
    "        joint[xb, yb] += 1.0\n",
    "    joint /= max(N, 1)\n",
    "\n",
    "    px = joint.sum(axis=1, keepdims=True)\n",
    "    py = joint.sum(axis=0, keepdims=True)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = joint / (px @ py + eps)\n",
    "        term = joint * np.log(np.clip(ratio, eps, None))\n",
    "\n",
    "    mi = np.nansum(term)\n",
    "    return float(mi)\n",
    "\n",
    "def load_sample(sample_path, expected_shape):\n",
    "    \"\"\"Load sample matching expected (H,W,C). If None, create synthetic in [0,1].\"\"\"\n",
    "    H, W, C = expected_shape\n",
    "    if sample_path is not None and os.path.isfile(sample_path):\n",
    "        x = np.load(sample_path)\n",
    "        if x.shape != (H, W, C):\n",
    "            raise ValueError(f\"Expected sample shape {(H,W,C)}, got {x.shape}\")\n",
    "        return x.astype(np.float32)[None, ...]\n",
    "    # Fallback synthetic sample in [0,1]\n",
    "    rng = np.random.RandomState(0)\n",
    "    x = rng.rand(H, W, C).astype(np.float32)\n",
    "    return x[None, ...]\n",
    "\n",
    "class MIMEPredictor:\n",
    "    def __init__(self, model, head_tensor, h, w, c):\n",
    "        # Build a submodel that outputs the classification head\n",
    "        if isinstance(model.inputs, (list, tuple)):\n",
    "            inputs_for_submodel = list(model.inputs)\n",
    "        else:\n",
    "            inputs_for_submodel = [model.input]\n",
    "        self.head_model = tf.keras.Model(inputs=inputs_for_submodel, outputs=head_tensor)\n",
    "\n",
    "        # Keep input meta for passing the right structure later\n",
    "        self._single_input = (len(self.head_model.inputs) == 1)\n",
    "        self._input_names = getattr(self.head_model, \"input_names\", None)\n",
    "\n",
    "        # Fixed input signature to avoid retracing\n",
    "        self._sig = tf.TensorSpec(shape=[None, h, w, c], dtype=tf.float32)\n",
    "\n",
    "        @tf.function(reduce_retracing=True, input_signature=[self._sig])\n",
    "        def _predict_tf(x):\n",
    "            # Match the model's expected input structure:\n",
    "            if self._single_input:\n",
    "                # Option 1 (usually enough to remove the warning): wrap as a list\n",
    "                return self.head_model([x], training=False)\n",
    "\n",
    "                # Option 2 (even stricter by name; uncomment if you still see warnings)\n",
    "                # if self._input_names:\n",
    "                #     return self.head_model({self._input_names[0]: x}, training=False)\n",
    "                # else:\n",
    "                #     return self.head_model([x], training=False)\n",
    "            else:\n",
    "                # If you ever have multi-input, you'd map tensors accordingly here.\n",
    "                raise ValueError(\"This predictor currently supports single-input models only.\")\n",
    "\n",
    "        self._predict_tf = _predict_tf\n",
    "\n",
    "    def probs(self, xb_np):\n",
    "        x = tf.convert_to_tensor(xb_np, dtype=tf.float32)\n",
    "        out = self._predict_tf(x).numpy()\n",
    "        return ensure_softmax_probs(out)\n",
    "\n",
    "# =========================\n",
    "# MIME (local MI) explanation\n",
    "# =========================\n",
    "def mime_local_importance(predictor, x1, class_to_explain='pred',\n",
    "                          k=80, perturb_std_frac=0.10, n_bins=10,\n",
    "                          clip_min=0.0, clip_max=1.0):\n",
    "    base_probs = predictor.probs(x1)  # (1, C)\n",
    "    num_classes = base_probs.shape[-1]\n",
    "    if class_to_explain == 'pred':\n",
    "        explained_class = int(np.argmax(base_probs[0]))\n",
    "    else:\n",
    "        explained_class = int(class_to_explain)\n",
    "        if explained_class < 0 or explained_class >= num_classes:\n",
    "            raise ValueError(f\"class_to_explain out of range: {explained_class}\")\n",
    "\n",
    "    H, W, C = x1.shape[1:]\n",
    "    mi_map = np.zeros((H, W, C), dtype=np.float32)\n",
    "\n",
    "    vmin, vmax = float(np.min(x1)), float(np.max(x1))\n",
    "    if vmax == vmin:\n",
    "        vmax = vmin + 1.0\n",
    "    value_range = max(vmax - vmin, 1e-6)\n",
    "    sigma = perturb_std_frac * value_range\n",
    "\n",
    "    xb = np.repeat(x1.astype(np.float32), repeats=k, axis=0)  # (k,H,W,C), fixed shape\n",
    "\n",
    "    total_feats = H * W * C\n",
    "    idx = 0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            for ch in range(C):\n",
    "                base_val = float(x1[0, i, j, ch])\n",
    "                noise = np.random.normal(loc=0.0, scale=sigma, size=(k,))\n",
    "                pert_vals = np.clip(base_val + noise, clip_min, clip_max).astype(np.float32)\n",
    "\n",
    "                xb[:] = x1\n",
    "                xb[:, i, j, ch] = pert_vals\n",
    "\n",
    "                probs = predictor.probs(xb)          # (k, C)\n",
    "                y = probs[:, explained_class]        # (k,)\n",
    "\n",
    "                x_bins, _, _ = discretize(pert_vals, n_bins)\n",
    "                y_bins, _, _ = discretize(y, n_bins)\n",
    "                mi = mutual_information_discrete(x_bins, y_bins, n_bins, n_bins)\n",
    "                mi_map[i, j, ch] = mi\n",
    "\n",
    "                idx += 1\n",
    "                if idx % 50 == 0:\n",
    "                    print(f\"[MIME] Processed {idx}/{total_feats} features...\")\n",
    "\n",
    "    return mi_map, explained_class\n",
    "\n",
    "# =========================\n",
    "# Plotting helpers\n",
    "# =========================\n",
    "def plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR):\n",
    "    H, W, C = mi_map.shape\n",
    "\n",
    "    # Aggregate views\n",
    "    per_pixel = mi_map.sum(axis=2)\n",
    "    per_channel = mi_map.sum(axis=(0,1))\n",
    "\n",
    "    def _normalize(a):\n",
    "        a = np.asarray(a, dtype=float)\n",
    "        m, M = np.min(a), np.max(a)\n",
    "        if M > m:\n",
    "            return (a - m) / (M - m + 1e-12)\n",
    "        return np.zeros_like(a)\n",
    "\n",
    "    # Custom colormap\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap = LinearSegmentedColormap.from_list(\"wlb\", [\"white\", \"lightblue\", \"blue\"])\n",
    "\n",
    "    # Choose channel names safely\n",
    "    if len(CHANNEL_NAMES_DEFAULT) == C:\n",
    "        channel_names = CHANNEL_NAMES_DEFAULT\n",
    "    else:\n",
    "        channel_names = [f\"channel_{i}\" for i in range(C)]\n",
    "\n",
    "    # Per-pixel heatmap\n",
    "    fig = plt.figure(figsize=(5,4))\n",
    "    im = plt.imshow(_normalize(per_pixel), interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f\"MIME per-pixel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.colorbar(im, label=\"normalized MI\")\n",
    "    plt.xticks(range(W)); plt.yticks(range(H))\n",
    "    path_pixel = os.path.join(outdir, f\"{H}x{W}_e_bi_per_pixel_class_{explained_class}.png\")\n",
    "    plt.savefig(path_pixel, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Per-channel bar\n",
    "    fig = plt.figure(figsize=(max(6, C*0.7), 4))\n",
    "    xs = np.arange(C)\n",
    "    plt.bar(xs, per_channel)\n",
    "    plt.xlabel(\"Channel\")\n",
    "    plt.ylabel(\"MI (sum over spatial)\")\n",
    "    plt.title(f\"MIME per-channel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.xticks(xs, channel_names, rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    path_chan = os.path.join(outdir, f\"{H}x{W}_e_bi_per_channel_class_{explained_class}.png\")\n",
    "    plt.savefig(path_chan, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Grid of channel heatmaps\n",
    "    import matplotlib.colors as mcolors\n",
    "    vmin = float(np.min(mi_map))\n",
    "    vmax = float(np.max(mi_map))\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    n_cols = 4\n",
    "    n_rows = int(math.ceil(C / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "    axs = np.atleast_1d(axs).reshape(n_rows, n_cols)\n",
    "    im_last = None\n",
    "    for ch in range(C):\n",
    "        r, c = divmod(ch, n_cols)\n",
    "        ax = axs[r, c]\n",
    "        im_last = ax.imshow(mi_map[:,:,ch], interpolation='nearest', norm=norm, cmap=cmap)\n",
    "        ax.set_title(channel_names[ch], fontsize=9)\n",
    "        ax.set_xticks(range(W)); ax.set_yticks(range(H))\n",
    "    for idx in range(C, n_rows*n_cols):\n",
    "        r, c = divmod(idx, n_cols)\n",
    "        axs[r, c].axis(\"off\")\n",
    "    cbar = fig.colorbar(im_last, ax=axs, shrink=0.95, pad=0.02)\n",
    "    cbar.set_label(\"Mutual Information (MI)\")\n",
    "    fig.suptitle(f\"MIME per-feature MI by channel (class {explained_class}) [{H}x{W}]\", y=0.995, fontsize=12)\n",
    "    path_grid = os.path.join(outdir, f\"{H}x{W}_e_bi_per_channel_grid_class_{explained_class}.png\")\n",
    "    plt.savefig(path_grid, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"[MIME] Saved:\")\n",
    "    print(\" -\", path_pixel)\n",
    "    print(\" -\", path_chan)\n",
    "    print(\" -\", path_grid)\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    # Infer (H, W, C) from the model\n",
    "    _, H, W, C = model.input_shape\n",
    "    print(f\"[INFO] Model expects input shape: (None, {H}, {W}, {C})\")\n",
    "\n",
    "    # Build predictor with the correct spatial dims and channels\n",
    "    head = pick_classification_head(model, prefer_name=\"classification_output\")\n",
    "    predictor = MIMEPredictor(model, head_tensor=head, h=H, w=W, c=C)\n",
    "\n",
    "    # Load sample of correct shape (or synthesize)\n",
    "    x1 = load_sample(SAMPLE_NPY, expected_shape=(H, W, C)).astype(np.float32)\n",
    "    x1 = np.clip(x1, CLIP_MIN, CLIP_MAX)\n",
    "\n",
    "    # Peek prediction (uses cached predictor)\n",
    "    base_probs = predictor.probs(x1)\n",
    "    cexp = 1\n",
    "\n",
    "    mi_map, explained_class = mime_local_importance(\n",
    "        predictor, x1,\n",
    "        class_to_explain=cexp,\n",
    "        k=K,\n",
    "        perturb_std_frac=PERTURB_STD_FRAC,\n",
    "        n_bins=N_BINS,\n",
    "        clip_min=CLIP_MIN,\n",
    "        clip_max=CLIP_MAX\n",
    "    )\n",
    "\n",
    "    print(f\"[RESULT] mi_map shape: {mi_map.shape}\")\n",
    "    print(f\"[RESULT] explained_class: {explained_class}\")\n",
    "    print(f\"[RESULT] total MI sum: {mi_map.sum():.6f}\")\n",
    "\n",
    "    plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5287c31b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model expects input shape: (None, 7, 7, 12)\n",
      "[INFO] Predicted probs: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[INFO] Explaining class: 0\n",
      "[MIME] Processed 100/588 features...\n",
      "[MIME] Processed 200/588 features...\n",
      "[MIME] Processed 300/588 features...\n",
      "[MIME] Processed 400/588 features...\n",
      "[MIME] Processed 500/588 features...\n",
      "[RESULT] mi_map shape: (7, 7, 12)\n",
      "[RESULT] total MI sum: -0.000000\n",
      "[MIME] Saved 3 PNG visualizations.\n",
      "[INFO] PNGs saved in mime_explanations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "MODEL_PATH = os.path.join(\"models\", \"veremi_images_m_7x7_ea_i.keras\")\n",
    "\n",
    "SAMPLE_NPY = None          # e.g., r\"samples\\example_0001.npy\"\n",
    "FAC_IMAGE_DIR = \"veremi_multilevel_images_7x7_ea\"\n",
    "\n",
    "K = 80\n",
    "PERTURB_STD_FRAC = 0.10\n",
    "N_BINS = 10\n",
    "CLASS_TO_EXPLAIN = 'pred'\n",
    "\n",
    "CLIP_MIN, CLIP_MAX = 0.0, 1.0\n",
    "\n",
    "OUTDIR = \"mime_explanations\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "CHANNEL_NAMES_DEFAULT = [\n",
    "    \"sendTime\", \"sender\", \"posx\", \"posy\",\n",
    "    \"spdx_n\", \"spdy_n\", \"aclx\", \"acly\",\n",
    "    \"hedx\", \"hedy\", \"hedx_n\", \"hedy_n\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def pick_classification_head(model, prefer_name=None):\n",
    "    outputs = model.outputs\n",
    "    if isinstance(outputs, tf.Tensor):\n",
    "        return outputs\n",
    "    chosen = None\n",
    "    if prefer_name is not None and hasattr(model, \"output_names\"):\n",
    "        try:\n",
    "            idx = list(model.output_names).index(prefer_name)\n",
    "            chosen = outputs[idx]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if chosen is None:\n",
    "        for t in outputs:\n",
    "            try:\n",
    "                last = int(t.shape[-1])\n",
    "                if last >= 2:\n",
    "                    chosen = t\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    if chosen is None:\n",
    "        chosen = outputs[0]\n",
    "    return chosen\n",
    "\n",
    "def ensure_softmax_probs(logits_or_probs):\n",
    "    arr = np.asarray(logits_or_probs)\n",
    "    s = arr.sum(axis=-1, keepdims=True)\n",
    "    if np.all(arr >= -1e-6) and np.all(np.abs(s - 1.0) < 1e-3):\n",
    "        return arr\n",
    "    exps = np.exp(arr - np.max(arr, axis=-1, keepdims=True))\n",
    "    return exps / np.clip(exps.sum(axis=-1, keepdims=True), 1e-12, None)\n",
    "\n",
    "def discretize(values, n_bins):\n",
    "    v = np.asarray(values).ravel()\n",
    "    vmin, vmax = np.min(v), np.max(v)\n",
    "    if vmax == vmin:\n",
    "        return np.zeros_like(v, dtype=int), vmin, vmax\n",
    "    edges = np.linspace(vmin, vmax, n_bins + 1)\n",
    "    bins = np.clip(np.digitize(v, edges[:-1], right=False) - 1, 0, n_bins - 1)\n",
    "    return bins, vmin, vmax\n",
    "\n",
    "def mutual_information_discrete(x_bins, y_bins, n_x_bins, n_y_bins, eps=1e-12):\n",
    "    x_bins = np.asarray(x_bins).ravel()\n",
    "    y_bins = np.asarray(y_bins).ravel()\n",
    "    N = len(x_bins)\n",
    "    joint = np.zeros((n_x_bins, n_y_bins), dtype=float)\n",
    "    for xb, yb in zip(x_bins, y_bins):\n",
    "        joint[xb, yb] += 1.0\n",
    "    joint /= max(N, 1)\n",
    "    px = joint.sum(axis=1, keepdims=True)\n",
    "    py = joint.sum(axis=0, keepdims=True)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = joint / (px @ py + eps)\n",
    "        term = joint * np.log(np.clip(ratio, eps, None))\n",
    "    return float(np.nansum(term))\n",
    "\n",
    "def find_sample(sample_path, fallback_dir, expected_shape):\n",
    "    H, W, C = expected_shape\n",
    "    if sample_path and os.path.isfile(sample_path):\n",
    "        x = np.load(sample_path)\n",
    "        if x.shape != (H, W, C):\n",
    "            raise ValueError(f\"Expected {expected_shape}, got {x.shape}\")\n",
    "        return x.astype(np.float32)[None, ...]\n",
    "    if fallback_dir and os.path.isdir(fallback_dir):\n",
    "        candidates = sorted(glob.glob(os.path.join(fallback_dir, \"image_*.npy\")))\n",
    "        if not candidates:\n",
    "            candidates = sorted(glob.glob(os.path.join(fallback_dir, \"*.npy\")))\n",
    "        for fp in candidates:\n",
    "            try:\n",
    "                x = np.load(fp)\n",
    "                if x.shape == (H, W, C):\n",
    "                    return x.astype(np.float32)[None, ...]\n",
    "            except Exception:\n",
    "                pass\n",
    "    # Fallback synthetic\n",
    "    rng = np.random.RandomState(0)\n",
    "    x = rng.rand(H, W, C).astype(np.float32)\n",
    "    return x[None, ...]\n",
    "\n",
    "class MIMEPredictor:\n",
    "    def __init__(self, model, head_tensor, h, w, c):\n",
    "        if isinstance(model.inputs, (list, tuple)):\n",
    "            inputs_for_submodel = list(model.inputs)\n",
    "        else:\n",
    "            inputs_for_submodel = [model.input]\n",
    "        self.head_model = tf.keras.Model(inputs=inputs_for_submodel, outputs=head_tensor)\n",
    "        self._single_input = (len(self.head_model.inputs) == 1)\n",
    "        self._input_names = getattr(self.head_model, \"input_names\", None)\n",
    "        self._sig = tf.TensorSpec(shape=[None, h, w, c], dtype=tf.float32)\n",
    "\n",
    "        @tf.function(reduce_retracing=True, input_signature=[self._sig])\n",
    "        def _predict_tf(x):\n",
    "            # Feed as list to match the recorded input structure (avoids warnings)\n",
    "            if self._single_input:\n",
    "                return self.head_model([x], training=False)\n",
    "            else:\n",
    "                raise ValueError(\"Only single-input models are supported.\")\n",
    "        self._predict_tf = _predict_tf\n",
    "\n",
    "    def probs(self, xb_np):\n",
    "        x = tf.convert_to_tensor(xb_np, dtype=tf.float32)\n",
    "        out = self._predict_tf(x).numpy()\n",
    "        return ensure_softmax_probs(out)\n",
    "\n",
    "# =========================\n",
    "# MIME explanation\n",
    "# =========================\n",
    "def mime_local_importance(predictor, x1, class_to_explain='pred',\n",
    "                          k=80, perturb_std_frac=0.10, n_bins=10,\n",
    "                          clip_min=0.0, clip_max=1.0):\n",
    "    base_probs = predictor.probs(x1)\n",
    "    num_classes = base_probs.shape[-1]\n",
    "    if class_to_explain == 'pred':\n",
    "        explained_class = int(np.argmax(base_probs[0]))\n",
    "    else:\n",
    "        explained_class = int(class_to_explain)\n",
    "\n",
    "    H, W, C = x1.shape[1:]\n",
    "    mi_map = np.zeros((H, W, C), dtype=np.float32)\n",
    "\n",
    "    vmin, vmax = float(np.min(x1)), float(np.max(x1))\n",
    "    if vmax == vmin:\n",
    "        vmax = vmin + 1.0\n",
    "    value_range = max(vmax - vmin, 1e-6)\n",
    "    sigma = perturb_std_frac * value_range\n",
    "\n",
    "    xb = np.repeat(x1.astype(np.float32), repeats=k, axis=0)\n",
    "\n",
    "    total_feats = H * W * C\n",
    "    idx = 0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            for ch in range(C):\n",
    "                base_val = float(x1[0, i, j, ch])\n",
    "                noise = np.random.normal(loc=0.0, scale=sigma, size=(k,))\n",
    "                pert_vals = np.clip(base_val + noise, clip_min, clip_max).astype(np.float32)\n",
    "                xb[:] = x1\n",
    "                xb[:, i, j, ch] = pert_vals\n",
    "                probs = predictor.probs(xb)\n",
    "                y = probs[:, explained_class]\n",
    "                x_bins, _, _ = discretize(pert_vals, n_bins)\n",
    "                y_bins, _, _ = discretize(y, n_bins)\n",
    "                mi = mutual_information_discrete(x_bins, y_bins, n_bins, n_bins)\n",
    "                mi_map[i, j, ch] = mi\n",
    "                idx += 1\n",
    "                if idx % 100 == 0:\n",
    "                    print(f\"[MIME] Processed {idx}/{total_feats} features...\")\n",
    "    return mi_map, explained_class\n",
    "\n",
    "# =========================\n",
    "# Plotting\n",
    "# =========================\n",
    "def _normalize(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    m, M = np.min(a), np.max(a)\n",
    "    if M > m:\n",
    "        return (a - m) / (M - m + 1e-12)\n",
    "    return np.zeros_like(a)\n",
    "\n",
    "def plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR, tag=\"\"):\n",
    "    H, W, C = mi_map.shape\n",
    "    channel_names = CHANNEL_NAMES_DEFAULT if len(CHANNEL_NAMES_DEFAULT) == C else [f\"channel_{i}\" for i in range(C)]\n",
    "\n",
    "    per_pixel = mi_map.sum(axis=2)\n",
    "    per_channel = mi_map.sum(axis=(0,1))\n",
    "\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap = LinearSegmentedColormap.from_list(\"wlb\", [\"white\", \"lightblue\", \"blue\"])\n",
    "\n",
    "    # Per-pixel heatmap\n",
    "    fig = plt.figure(figsize=(5.5, 4.5))\n",
    "    im = plt.imshow(_normalize(per_pixel), interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f\"MIME per-pixel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.colorbar(im, label=\"normalized MI\")\n",
    "    plt.xticks(range(W)); plt.yticks(range(H))\n",
    "    plt.savefig(os.path.join(outdir, f\"{H}x{W}_ea_mi_per_pixel_class_{explained_class}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Per-channel bar\n",
    "    fig = plt.figure(figsize=(max(8, C*0.7), 4.5))\n",
    "    xs = np.arange(C)\n",
    "    plt.bar(xs, per_channel)\n",
    "    plt.xlabel(\"Channel\")\n",
    "    plt.ylabel(\"MI (sum over spatial)\")\n",
    "    plt.title(f\"MIME per-channel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.xticks(xs, channel_names, rotation=45, ha=\"right\")\n",
    "    plt.savefig(os.path.join(outdir, f\"{H}x{W}_ea_mi_per_channel_class_{explained_class}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Grid of channel heatmaps\n",
    "    import matplotlib.colors as mcolors\n",
    "    vmin = float(np.min(mi_map)); vmax = float(np.max(mi_map))\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    n_cols = 4\n",
    "    n_rows = int(math.ceil(C / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "    axs = np.atleast_1d(axs).reshape(n_rows, n_cols)\n",
    "    im_last = None\n",
    "    for ch in range(C):\n",
    "        r, c = divmod(ch, n_cols)\n",
    "        ax = axs[r, c]\n",
    "        im_last = ax.imshow(mi_map[:,:,ch], interpolation='nearest', norm=norm, cmap=cmap)\n",
    "        ax.set_title(channel_names[ch], fontsize=9)\n",
    "        ax.set_xticks(range(W)); ax.set_yticks(range(H))\n",
    "    for idx in range(C, n_rows*n_cols):\n",
    "        r, c = divmod(idx, n_cols)\n",
    "        axs[r, c].axis(\"off\")\n",
    "    cbar = fig.colorbar(im_last, ax=axs, shrink=0.95, pad=0.02)\n",
    "    cbar.set_label(\"Mutual Information (MI)\")\n",
    "    fig.suptitle(f\"MIME per-feature MI by channel (class {explained_class}) [{H}x{W}]\", y=0.995, fontsize=12)\n",
    "    plt.savefig(os.path.join(outdir, f\"{H}x{W}_ea_mi_per_channel_grid_class_{explained_class}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"[MIME] Saved 3 PNG visualizations.\")\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "def main():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    # Infer expected (H, W, C) from model input\n",
    "    _, H, W, C = model.input_shape\n",
    "    print(f\"[INFO] Model expects input shape: (None, {H}, {W}, {C})\")\n",
    "\n",
    "    head = pick_classification_head(model, prefer_name=\"classification_output\")\n",
    "    predictor = MIMEPredictor(model, head_tensor=head, h=H, w=W, c=C)\n",
    "\n",
    "    # Load sample matching the model's expected shape (or synthesize)\n",
    "    x1 = find_sample(SAMPLE_NPY, FAC_IMAGE_DIR, expected_shape=(H, W, C))\n",
    "    x1 = np.clip(x1, CLIP_MIN, CLIP_MAX).astype(np.float32)\n",
    "\n",
    "    base_probs = predictor.probs(x1)\n",
    "    print(f\"[INFO] Predicted probs: {np.round(base_probs[0], 6)}\")\n",
    "    cexp = 0\n",
    "    print(f\"[INFO] Explaining class: {cexp}\")\n",
    "\n",
    "    mi_map, explained_class = mime_local_importance(\n",
    "        predictor, x1,\n",
    "        class_to_explain=cexp,\n",
    "        k=K,\n",
    "        perturb_std_frac=PERTURB_STD_FRAC,\n",
    "        n_bins=N_BINS,\n",
    "        clip_min=CLIP_MIN,\n",
    "        clip_max=CLIP_MAX\n",
    "    )\n",
    "    print(f\"[RESULT] mi_map shape: {mi_map.shape}\")\n",
    "    print(f\"[RESULT] total MI sum: {mi_map.sum():.6f}\")\n",
    "\n",
    "    # Tag filenames with directory hint if useful\n",
    "    tag = \"\" if not FAC_IMAGE_DIR else f\"_{os.path.basename(FAC_IMAGE_DIR)}\"\n",
    "    plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR, tag=tag)\n",
    "    print(f\"[INFO] PNGs saved in {OUTDIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8bbffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model expects input shape: (None, 7, 7, 12)\n",
      "[INFO] Predicted probs: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[INFO] Explaining class: 19\n",
      "[MIME] Processed 100/588 features...\n",
      "[MIME] Processed 200/588 features...\n",
      "[MIME] Processed 300/588 features...\n",
      "[MIME] Processed 400/588 features...\n",
      "[MIME] Processed 500/588 features...\n",
      "[RESULT] mi_map shape: (7, 7, 12)\n",
      "[RESULT] total MI sum: -0.000000\n",
      "[MIME] Saved 3 PNG visualizations.\n",
      "[INFO] PNGs saved in mime_explanations\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "MODEL_PATH = os.path.join(\"models\", \"veremi_images_m_7x7_ea_i.keras\")\n",
    "\n",
    "SAMPLE_NPY = None          # e.g., r\"samples\\example_0001.npy\"\n",
    "FAC_IMAGE_DIR = \"veremi_multilevel_images_7x7_ea\"\n",
    "\n",
    "K = 80\n",
    "PERTURB_STD_FRAC = 0.10\n",
    "N_BINS = 10\n",
    "CLASS_TO_EXPLAIN = 'pred'\n",
    "\n",
    "CLIP_MIN, CLIP_MAX = 0.0, 1.0\n",
    "\n",
    "OUTDIR = \"mime_explanations\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "CHANNEL_NAMES_DEFAULT = [\n",
    "    \"sendTime\", \"sender\", \"posx\", \"posy\",\n",
    "    \"spdx_n\", \"spdy_n\", \"aclx\", \"acly\",\n",
    "    \"hedx\", \"hedy\", \"hedx_n\", \"hedy_n\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def pick_classification_head(model, prefer_name=None):\n",
    "    outputs = model.outputs\n",
    "    if isinstance(outputs, tf.Tensor):\n",
    "        return outputs\n",
    "    chosen = None\n",
    "    if prefer_name is not None and hasattr(model, \"output_names\"):\n",
    "        try:\n",
    "            idx = list(model.output_names).index(prefer_name)\n",
    "            chosen = outputs[idx]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if chosen is None:\n",
    "        for t in outputs:\n",
    "            try:\n",
    "                last = int(t.shape[-1])\n",
    "                if last >= 2:\n",
    "                    chosen = t\n",
    "                    break\n",
    "            except Exception:\n",
    "                continue\n",
    "    if chosen is None:\n",
    "        chosen = outputs[0]\n",
    "    return chosen\n",
    "\n",
    "def ensure_softmax_probs(logits_or_probs):\n",
    "    arr = np.asarray(logits_or_probs)\n",
    "    s = arr.sum(axis=-1, keepdims=True)\n",
    "    if np.all(arr >= -1e-6) and np.all(np.abs(s - 1.0) < 1e-3):\n",
    "        return arr\n",
    "    exps = np.exp(arr - np.max(arr, axis=-1, keepdims=True))\n",
    "    return exps / np.clip(exps.sum(axis=-1, keepdims=True), 1e-12, None)\n",
    "\n",
    "def discretize(values, n_bins):\n",
    "    v = np.asarray(values).ravel()\n",
    "    vmin, vmax = np.min(v), np.max(v)\n",
    "    if vmax == vmin:\n",
    "        return np.zeros_like(v, dtype=int), vmin, vmax\n",
    "    edges = np.linspace(vmin, vmax, n_bins + 1)\n",
    "    bins = np.clip(np.digitize(v, edges[:-1], right=False) - 1, 0, n_bins - 1)\n",
    "    return bins, vmin, vmax\n",
    "\n",
    "def mutual_information_discrete(x_bins, y_bins, n_x_bins, n_y_bins, eps=1e-12):\n",
    "    x_bins = np.asarray(x_bins).ravel()\n",
    "    y_bins = np.asarray(y_bins).ravel()\n",
    "    N = len(x_bins)\n",
    "    joint = np.zeros((n_x_bins, n_y_bins), dtype=float)\n",
    "    for xb, yb in zip(x_bins, y_bins):\n",
    "        joint[xb, yb] += 1.0\n",
    "    joint /= max(N, 1)\n",
    "    px = joint.sum(axis=1, keepdims=True)\n",
    "    py = joint.sum(axis=0, keepdims=True)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        ratio = joint / (px @ py + eps)\n",
    "        term = joint * np.log(np.clip(ratio, eps, None))\n",
    "    return float(np.nansum(term))\n",
    "\n",
    "def find_sample(sample_path, fallback_dir, expected_shape):\n",
    "    H, W, C = expected_shape\n",
    "    if sample_path and os.path.isfile(sample_path):\n",
    "        x = np.load(sample_path)\n",
    "        if x.shape != (H, W, C):\n",
    "            raise ValueError(f\"Expected {expected_shape}, got {x.shape}\")\n",
    "        return x.astype(np.float32)[None, ...]\n",
    "    if fallback_dir and os.path.isdir(fallback_dir):\n",
    "        candidates = sorted(glob.glob(os.path.join(fallback_dir, \"image_*.npy\")))\n",
    "        if not candidates:\n",
    "            candidates = sorted(glob.glob(os.path.join(fallback_dir, \"*.npy\")))\n",
    "        for fp in candidates:\n",
    "            try:\n",
    "                x = np.load(fp)\n",
    "                if x.shape == (H, W, C):\n",
    "                    return x.astype(np.float32)[None, ...]\n",
    "            except Exception:\n",
    "                pass\n",
    "    # Fallback synthetic\n",
    "    rng = np.random.RandomState(0)\n",
    "    x = rng.rand(H, W, C).astype(np.float32)\n",
    "    return x[None, ...]\n",
    "\n",
    "class MIMEPredictor:\n",
    "    def __init__(self, model, head_tensor, h, w, c):\n",
    "        if isinstance(model.inputs, (list, tuple)):\n",
    "            inputs_for_submodel = list(model.inputs)\n",
    "        else:\n",
    "            inputs_for_submodel = [model.input]\n",
    "        self.head_model = tf.keras.Model(inputs=inputs_for_submodel, outputs=head_tensor)\n",
    "        self._single_input = (len(self.head_model.inputs) == 1)\n",
    "        self._input_names = getattr(self.head_model, \"input_names\", None)\n",
    "        self._sig = tf.TensorSpec(shape=[None, h, w, c], dtype=tf.float32)\n",
    "\n",
    "        @tf.function(reduce_retracing=True, input_signature=[self._sig])\n",
    "        def _predict_tf(x):\n",
    "            # Feed as list to match the recorded input structure (avoids warnings)\n",
    "            if self._single_input:\n",
    "                return self.head_model([x], training=False)\n",
    "            else:\n",
    "                raise ValueError(\"Only single-input models are supported.\")\n",
    "        self._predict_tf = _predict_tf\n",
    "\n",
    "    def probs(self, xb_np):\n",
    "        x = tf.convert_to_tensor(xb_np, dtype=tf.float32)\n",
    "        out = self._predict_tf(x).numpy()\n",
    "        return ensure_softmax_probs(out)\n",
    "\n",
    "# =========================\n",
    "# MIME explanation\n",
    "# =========================\n",
    "def mime_local_importance(predictor, x1, class_to_explain='pred',\n",
    "                          k=80, perturb_std_frac=0.10, n_bins=10,\n",
    "                          clip_min=0.0, clip_max=1.0):\n",
    "    base_probs = predictor.probs(x1)\n",
    "    num_classes = base_probs.shape[-1]\n",
    "    if class_to_explain == 'pred':\n",
    "        explained_class = int(np.argmax(base_probs[0]))\n",
    "    else:\n",
    "        explained_class = int(class_to_explain)\n",
    "\n",
    "    H, W, C = x1.shape[1:]\n",
    "    mi_map = np.zeros((H, W, C), dtype=np.float32)\n",
    "\n",
    "    vmin, vmax = float(np.min(x1)), float(np.max(x1))\n",
    "    if vmax == vmin:\n",
    "        vmax = vmin + 1.0\n",
    "    value_range = max(vmax - vmin, 1e-6)\n",
    "    sigma = perturb_std_frac * value_range\n",
    "\n",
    "    xb = np.repeat(x1.astype(np.float32), repeats=k, axis=0)\n",
    "\n",
    "    total_feats = H * W * C\n",
    "    idx = 0\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            for ch in range(C):\n",
    "                base_val = float(x1[0, i, j, ch])\n",
    "                noise = np.random.normal(loc=0.0, scale=sigma, size=(k,))\n",
    "                pert_vals = np.clip(base_val + noise, clip_min, clip_max).astype(np.float32)\n",
    "                xb[:] = x1\n",
    "                xb[:, i, j, ch] = pert_vals\n",
    "                probs = predictor.probs(xb)\n",
    "                y = probs[:, explained_class]\n",
    "                x_bins, _, _ = discretize(pert_vals, n_bins)\n",
    "                y_bins, _, _ = discretize(y, n_bins)\n",
    "                mi = mutual_information_discrete(x_bins, y_bins, n_bins, n_bins)\n",
    "                mi_map[i, j, ch] = mi\n",
    "                idx += 1\n",
    "                if idx % 100 == 0:\n",
    "                    print(f\"[MIME] Processed {idx}/{total_feats} features...\")\n",
    "    return mi_map, explained_class\n",
    "\n",
    "# =========================\n",
    "# Plotting\n",
    "# =========================\n",
    "def _normalize(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    m, M = np.min(a), np.max(a)\n",
    "    if M > m:\n",
    "        return (a - m) / (M - m + 1e-12)\n",
    "    return np.zeros_like(a)\n",
    "\n",
    "def plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR, tag=\"\"):\n",
    "    H, W, C = mi_map.shape\n",
    "    channel_names = CHANNEL_NAMES_DEFAULT if len(CHANNEL_NAMES_DEFAULT) == C else [f\"channel_{i}\" for i in range(C)]\n",
    "\n",
    "    per_pixel = mi_map.sum(axis=2)\n",
    "    per_channel = mi_map.sum(axis=(0,1))\n",
    "\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap = LinearSegmentedColormap.from_list(\"wlb\", [\"white\", \"lightblue\", \"blue\"])\n",
    "\n",
    "    # Per-pixel heatmap\n",
    "    fig = plt.figure(figsize=(5.5, 4.5))\n",
    "    im = plt.imshow(_normalize(per_pixel), interpolation='nearest', cmap=cmap)\n",
    "    plt.title(f\"MIME per-pixel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.colorbar(im, label=\"normalized MI\")\n",
    "    plt.xticks(range(W)); plt.yticks(range(H))\n",
    "    plt.savefig(os.path.join(outdir, f\"{H}x{W}_ea_mi_per_pixel_class_{explained_class}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Per-channel bar\n",
    "    fig = plt.figure(figsize=(max(8, C*0.7), 4.5))\n",
    "    xs = np.arange(C)\n",
    "    plt.bar(xs, per_channel)\n",
    "    plt.xlabel(\"Channel\")\n",
    "    plt.ylabel(\"MI (sum over spatial)\")\n",
    "    plt.title(f\"MIME per-channel MI (class {explained_class}) [{H}x{W}]\")\n",
    "    plt.xticks(xs, channel_names, rotation=45, ha=\"right\")\n",
    "    plt.savefig(os.path.join(outdir, f\"{H}x{W}_ea_mi_per_channel_class_{explained_class}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Grid of channel heatmaps\n",
    "    import matplotlib.colors as mcolors\n",
    "    vmin = float(np.min(mi_map)); vmax = float(np.max(mi_map))\n",
    "    norm = mcolors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    n_cols = 4\n",
    "    n_rows = int(math.ceil(C / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(3*n_cols, 3*n_rows))\n",
    "    axs = np.atleast_1d(axs).reshape(n_rows, n_cols)\n",
    "    im_last = None\n",
    "    for ch in range(C):\n",
    "        r, c = divmod(ch, n_cols)\n",
    "        ax = axs[r, c]\n",
    "        im_last = ax.imshow(mi_map[:,:,ch], interpolation='nearest', norm=norm, cmap=cmap)\n",
    "        ax.set_title(channel_names[ch], fontsize=9)\n",
    "        ax.set_xticks(range(W)); ax.set_yticks(range(H))\n",
    "    for idx in range(C, n_rows*n_cols):\n",
    "        r, c = divmod(idx, n_cols)\n",
    "        axs[r, c].axis(\"off\")\n",
    "    cbar = fig.colorbar(im_last, ax=axs, shrink=0.95, pad=0.02)\n",
    "    cbar.set_label(\"Mutual Information (MI)\")\n",
    "    fig.suptitle(f\"MIME per-feature MI by channel (class {explained_class}) [{H}x{W}]\", y=0.995, fontsize=12)\n",
    "    plt.savefig(os.path.join(outdir, f\"{H}x{W}_ea_mi_per_channel_grid_class_{explained_class}.png\"), dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(\"[MIME] Saved 3 PNG visualizations.\")\n",
    "\n",
    "def main():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "    # Infer expected (H, W, C) from model input\n",
    "    _, H, W, C = model.input_shape\n",
    "    print(f\"[INFO] Model expects input shape: (None, {H}, {W}, {C})\")\n",
    "\n",
    "    head = pick_classification_head(model, prefer_name=\"classification_output\")\n",
    "    predictor = MIMEPredictor(model, head_tensor=head, h=H, w=W, c=C)\n",
    "\n",
    "    # Load sample matching the model's expected shape (or synthesize)\n",
    "    x1 = find_sample(SAMPLE_NPY, FAC_IMAGE_DIR, expected_shape=(H, W, C))\n",
    "    x1 = np.clip(x1, CLIP_MIN, CLIP_MAX).astype(np.float32)\n",
    "\n",
    "    base_probs = predictor.probs(x1)\n",
    "    print(f\"[INFO] Predicted probs: {np.round(base_probs[0], 6)}\")\n",
    "    cexp = 19\n",
    "    print(f\"[INFO] Explaining class: {cexp}\")\n",
    "\n",
    "    mi_map, explained_class = mime_local_importance(\n",
    "        predictor, x1,\n",
    "        class_to_explain=cexp,\n",
    "        k=K,\n",
    "        perturb_std_frac=PERTURB_STD_FRAC,\n",
    "        n_bins=N_BINS,\n",
    "        clip_min=CLIP_MIN,\n",
    "        clip_max=CLIP_MAX\n",
    "    )\n",
    "    print(f\"[RESULT] mi_map shape: {mi_map.shape}\")\n",
    "    print(f\"[RESULT] total MI sum: {mi_map.sum():.6f}\")\n",
    "\n",
    "    # Tag filenames with directory hint if useful\n",
    "    tag = \"\" if not FAC_IMAGE_DIR else f\"_{os.path.basename(FAC_IMAGE_DIR)}\"\n",
    "    plot_and_save_mime(mi_map, explained_class, outdir=OUTDIR, tag=tag)\n",
    "    print(f\"[INFO] PNGs saved in {OUTDIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5f8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
